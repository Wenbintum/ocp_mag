{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b05f44a-b73a-4fb6-a2c1-63a26bf7be20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/w/wenxu/.conda/envs/ocp-cu117/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n",
    "\n",
    "import umap\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR, CosineAnnealingLR\n",
    "import wandb\n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve1d\n",
    "from collections import Counter\n",
    "from pymatgen.core import Structure\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch.utils.data import Dataset as DS  # collision\n",
    "from torch_geometric.utils.convert import (\n",
    "    to_scipy_sparse_matrix,\n",
    ")  # for representation purposes\n",
    "from torch_geometric.utils import (\n",
    "    to_dense_adj,\n",
    "    to_dense_batch,\n",
    ")  # for representation purposes\n",
    "\n",
    "# For LDS\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# from utils import get_lds_kernel_window\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from ocpmodels.common.registry import registry\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# from utils import get_lds_kernel_window\n",
    "# from loss import weighted_mse_loss\n",
    "from torchmetrics import F1Score\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from data_model_utils import (\n",
    "    MyDataModule,\n",
    "    MyOwnDataset,\n",
    "    collate_fn,\n",
    "    data_list_collater,\n",
    "    ocp_model,\n",
    "    dimenet_model,\n",
    "    cgcnn_model,\n",
    "    gemnet_oc_segnn,\n",
    "    schnet_segnn,\n",
    "    schnet_model,\n",
    "    schnet_onehot,\n",
    "    schnet_onehot_inmag,\n",
    "    gemnet_oc_onehot,\n",
    "    gemnet_oc_onehot_inmag\n",
    ")\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3359773c-7254-4513-a076-68fdd4e6db4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MagmomClassifier(LightningModule):\n",
    "    def __init__(self, backbone, boundary, batch_size, energy_w = 1, magmom_w = 1):\n",
    "        super(MagmomClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.boundary = boundary\n",
    "        self.batch_size = batch_size\n",
    "        self.energy_w = energy_w\n",
    "        self.magmom_w = magmom_w\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        if not training:\n",
    "            self.backbone.eval()\n",
    "        #print(\"Module is in training?\", self.backbone.training)\n",
    "        magmoms = self.backbone(x)\n",
    "        return magmoms\n",
    "\n",
    "#multiplies the base initial learning rate\n",
    "#sqrt(global_batch_size/base_batch_size)\n",
    "#square-root learning rate scaling rule\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ReduceLROnPlateau(\n",
    "                    optimizer, mode=\"min\", patience=50, factor=0.5\n",
    "                ),\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        energy_preds, magmom_preds = self(batch)\n",
    "        energy_loss = nn.L1Loss()(\n",
    "            batch.corr_energy_per_atom,\n",
    "            energy_preds.squeeze().type(batch.corr_energy_per_atom.dtype),\n",
    "        ) \n",
    "        ind = torch.where(\n",
    "           torch.abs(batch.y) >= self.boundary\n",
    "        )  \n",
    "        magmom_preds = magmom_preds[ind]\n",
    "        magmom_loss = nn.L1Loss()(\n",
    "           batch.y[ind], magmom_preds.squeeze().type(batch.y.dtype)\n",
    "        )\n",
    "\n",
    "        energy_loss = self.energy_w*energy_loss\n",
    "        magmom_loss = self.magmom_w*magmom_loss\n",
    "        loss = energy_loss + magmom_loss\n",
    "\n",
    "        self.log(\"train_loss\", loss.item(), on_epoch=True, batch_size=self.batch_size)\n",
    "        self.log(\"magmom_loss_train\", magmom_loss, on_epoch=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        energy_preds, magmom_preds = self(batch)\n",
    "        energy_loss = nn.L1Loss()(\n",
    "            batch.corr_energy_per_atom,\n",
    "            energy_preds.squeeze().type(batch.corr_energy_per_atom.dtype),\n",
    "        ) \n",
    "        ind = torch.where(\n",
    "           torch.abs(batch.y) >= self.boundary\n",
    "        ) \n",
    "        magmom_preds = magmom_preds[ind]\n",
    "        magmom_loss_val = nn.L1Loss()(\n",
    "           batch.y[ind], magmom_preds.squeeze().type(batch.y.dtype)\n",
    "        ) #!wx\n",
    "\n",
    "        energy_loss = self.energy_w*energy_loss\n",
    "        magmom_loss_val = self.magmom_w*magmom_loss_val\n",
    "        val_loss = energy_loss + magmom_loss_val\n",
    "\n",
    "        self.log(\"val_loss\", val_loss.item(), on_epoch=True, batch_size=self.batch_size)\n",
    "        self.log(\"magmom_loss_val\", magmom_loss_val, on_epoch=True, batch_size=self.batch_size)\n",
    "        self.log(\"energy_loss_val\", energy_loss, on_epoch=True, batch_size=self.batch_size)\n",
    "\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            #    \"magmom_loss_val\": magmom_loss_val\n",
    "            # \"num_correct\": num_correct,\n",
    "            # \"num_samples\": num_samples,\n",
    "            # \"yhat\": preds,\n",
    "            # \"y\": y,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b20090-6c99-437b-8c5a-5acb619a8e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_2.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ec93fc-3b5c-42af-a7ca-f6ab6f616b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f18db7-f822-49e1-8832-9603bcb4f660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = \"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/magmom_checkpoints/right/Large_schnet_Einmag_all_application_91split_withoutoverlap-epoch=456-step=228043-val_loss=0.0257.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927b758d-98fc-4fe1-8842-7831146640fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/w/wenxu/.conda/envs/ocp-cu117/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n"
     ]
    }
   ],
   "source": [
    "classifier_model = MagmomClassifier.load_from_checkpoint(checkpoint_path=checkpoint,\n",
    "    backbone=schnet_onehot_inmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf4cb79-09ae-4f04-87c5-404c1c69b359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.natoms = torch.Tensor([64])\n",
    "n_neighbors = []\n",
    "n_index = data.edge_index[1, :]\n",
    "n_neighbors.append(n_index.shape[0])\n",
    "data.neighbors = torch.tensor(n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a32d6a8-a8e1-416e-b5b6-195fdc06a296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_preds, magmom_preds = classifier_model(data.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153005e3-70ce-4a04-8c27-a57abac21033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3589]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840f905c-2d1b-428a-b4df-1df1b82163e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: tensor([[-9.4068]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Step 0, Energy: -9.40684700012207\n",
      "Step 100, Energy: -9.438453674316406\n",
      "Step 200, Energy: -9.448260307312012\n",
      "Step 300, Energy: -9.448262214660645\n",
      "Step 400, Energy: -9.448262214660645\n",
      "Step 500, Energy: -9.448262214660645\n",
      "Step 600, Energy: -9.448262214660645\n",
      "Step 700, Energy: -9.448262214660645\n",
      "Step 800, Energy: -9.448262214660645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 90\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial:\u001b[39m\u001b[38;5;124m\"\u001b[39m, classifier_model(data)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#pretrained_model = classifier_model\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m final_spins, final_energy \u001b[38;5;241m=\u001b[39m \u001b[43mmonte_carlo_metropolis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mspins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mspins_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mclassifier_model\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 57\u001b[0m, in \u001b[0;36mmonte_carlo_metropolis\u001b[0;34m(data, spins, spins_magnitude, num_steps, temperature, pretrained_model)\u001b[0m\n\u001b[1;32m     55\u001b[0m i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_spins, (\u001b[38;5;241m1\u001b[39m,), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Randomly select a spin to flip\u001b[39;00m\n\u001b[1;32m     56\u001b[0m spins[i, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Flip the z-component of the spin\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m new_energy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspins_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m energy_change \u001b[38;5;241m=\u001b[39m new_energy \u001b[38;5;241m-\u001b[39m energy\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Metropolis criterion\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mcalculate_energy\u001b[0;34m(data, spins, spins_magnitude, pretrained_model)\u001b[0m\n\u001b[1;32m     18\u001b[0m data\u001b[38;5;241m.\u001b[39minmag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(spins_magnitude)\n\u001b[1;32m     19\u001b[0m data\u001b[38;5;241m.\u001b[39mmagft \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(spins)\n\u001b[0;32m---> 21\u001b[0m energy_preds, magmom_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpretrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m energy_preds\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mMagmomClassifier.forward\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(\"Module is in training?\", self.backbone.training)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m magmoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m magmoms\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/ocpmodels/models/schnet_onehot_inmag.py:253\u001b[0m, in \u001b[0;36mSchNetWrap.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregress_forces:\n\u001b[1;32m    252\u001b[0m     data\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 253\u001b[0m energy, _M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregress_forces:\n\u001b[1;32m    256\u001b[0m     forces \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    257\u001b[0m         torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m    258\u001b[0m             energy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m         )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m     )\n",
      "File \u001b[0;32m/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/ocpmodels/common/utils.py:135\u001b[0m, in \u001b[0;36mconditional_grad.<locals>.decorator.<locals>.cls_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregress_forces \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirect_forces\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    134\u001b[0m     f \u001b[38;5;241m=\u001b[39m dec(func)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/ocpmodels/models/schnet_onehot_inmag.py:230\u001b[0m, in \u001b[0;36mSchNetWrap._forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    226\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombined_emb(z, data\u001b[38;5;241m.\u001b[39mmagft[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlong(), data\u001b[38;5;241m.\u001b[39minmag)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m interaction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteractions:\n\u001b[0;32m--> 230\u001b[0m     h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[43minteraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# h = self.lin1(h)\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# h = self.act(h)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# h = self.lin2(h)\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_mlp_energy: \u001b[38;5;66;03m#!wx\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch_geometric/nn/models/schnet.py:378\u001b[0m, in \u001b[0;36mInteractionBlock.forward\u001b[0;34m(self, x, edge_index, edge_weight, edge_attr)\u001b[0m\n\u001b[1;32m    376\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, edge_index, edge_weight, edge_attr)\n\u001b[1;32m    377\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[0;32m--> 378\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/.conda/envs/ocp-cu117/lib/python3.9/site-packages/torch/nn/modules/module.py:1256\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_full_backward_hook\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_full_backward_hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1258\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def initial_state(num_spins):\n",
    "    \"\"\"Initialize spins randomly to either +1 or -1.\"\"\"\n",
    "    return np.random.choice([-1, 1], size=num_spins)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_energy(data, spins, spins_magnitude, pretrained_model):\n",
    "    \"\"\"Calculate the total energy of the spin system\"\"\"\n",
    "    data.natoms = torch.Tensor([64])\n",
    "    n_neighbors = []\n",
    "    n_index = data.edge_index[1, :]\n",
    "    n_neighbors.append(n_index.shape[0])\n",
    "    data.neighbors = torch.tensor(n_neighbors)\n",
    "    #update spin direction and spins_magnitude: try 1 don't change direction of spin, and change direction of spin\n",
    "    data.inmag = torch.Tensor(spins_magnitude)\n",
    "    data.magft = torch.Tensor(spins)\n",
    "    \n",
    "    energy_preds, magmom_preds = pretrained_model(data.to(\"cuda:0\"))\n",
    "    \n",
    "    return energy_preds\n",
    "\n",
    "def monte_carlo_metropolis(data, spins, spins_magnitude, num_steps, temperature, pretrained_model):\n",
    "    \"\"\"Perform Monte Carlo simulation using the Metropolis algorithm.\"\"\"\n",
    "    num_spins = spins.size(0)\n",
    "    energy = calculate_energy(data, spins, spins_magnitude, pretrained_model)\n",
    "    for step in range(num_steps):\n",
    "        i = torch.randint(0, num_spins, (1,), device='cuda')  # Randomly select a spin to flip\n",
    "        spins[i, 2] *= -1  # Flip the z-component of the spin\n",
    "        new_energy = calculate_energy(data, spins, spins_magnitude, pretrained_model)\n",
    "        energy_change = new_energy - energy\n",
    "        \n",
    "        # Metropolis criterion\n",
    "        if energy_change > 0 and torch.exp(-energy_change / temperature) < torch.rand(1, device='cuda'):\n",
    "            spins[i, 2] *= -1  # Revert flip\n",
    "        else:\n",
    "            energy = new_energy  # Accept new state and update energy\n",
    "        \n",
    "        # Optional: print or store energy and configuration every few steps if needed\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Energy: {energy.item()}\")\n",
    "\n",
    "    return spins, energy.item()\n",
    "\n",
    "\n",
    "n_spins = len(data.y)\n",
    "num_steps = 50000 #100000\n",
    "temperature = 0.0001\n",
    "\n",
    "data = torch.load(\"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_0.pt\").to(\"cuda:0\")\n",
    "spins_magnitude = data.inmag\n",
    "spins = data.magft\n",
    "\n",
    "data.natoms = torch.Tensor([64])\n",
    "n_neighbors = []\n",
    "n_index = data.edge_index[1, :]\n",
    "n_neighbors.append(n_index.shape[0])\n",
    "data.neighbors = torch.tensor(n_neighbors)\n",
    "print(\"Initial:\", classifier_model(data)[0])\n",
    "\n",
    "#pretrained_model = classifier_model\n",
    "\n",
    "final_spins, final_energy = monte_carlo_metropolis(\n",
    "                                 data,\n",
    "                                 spins, \n",
    "                                 spins_magnitude, \n",
    "                                 num_steps, \n",
    "                                 temperature,\n",
    "                                 classifier_model\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bfdb0231-e2c4-4aa2-992e-4690471be994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -0., -1.,  1.,  1.,\n",
       "         1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         1.,  1.,  1.,  1.,  0., -0.,  0., -0., -1., -1., -1., -1.,  0.,  0.,\n",
       "         0.,  0., -0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0., -0., -0.], device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_spins[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ac395f28-e814-4d47-bf1f-236200211ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(-1., device='cuda:0') tensor(2., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(1., device='cuda:0') tensor(-2., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(1., device='cuda:0') tensor(-2., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-1., device='cuda:0') tensor(-1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(0., device='cuda:0') tensor(-0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(-0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(-0., device='cuda:0') tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(previous_final_spins, final_spins):\n",
    "    print(i[2],j[2], i[2]-j[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9faf5943-346d-436a-b8bc-951acb6327d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = torch.load(\"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_0.pt\").to(\"cuda:0\")\n",
    "# for i, j in zip(final_spins, data.magft):\n",
    "#     print(i[2],j[2], i[2]-j[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79ece1a-a4dc-4ee7-9b1a-73e8006646c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(pos=[68, 3], cell=[1, 3, 3], atomic_numbers=[68], natoms=68, tags=[68], edge_index=[2, 3346], cell_offsets=[3346, 3], oc22=[1], y=[68], corr_energy_per_atom=0, frameid='Fe2O3_slab_110_AFM', mpid='Fe2O3_slab_110_AFM', inmag=[68], magft=[68, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(\"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_6.pt\").to(\"cuda:0\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f94d289-7e74-4c87-9590-1600b5943bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.2180, -4.2180, -4.1500, -4.1500,  4.2300,  4.2300,  4.1280,  4.1280,\n",
       "        -4.1970, -4.1970, -4.1980, -4.1980,  4.0870,  4.0880,  4.1870,  4.1870,\n",
       "        -3.5640, -3.5650, -4.2250, -4.2250,  3.7350,  3.7350,  4.2430,  4.2420,\n",
       "        -0.0490, -0.0490,  0.7670,  0.7670,  0.4210,  0.4210, -0.2010, -0.2010,\n",
       "        -0.5220, -0.5230, -0.4170, -0.4170,  0.0450,  0.0460,  0.0160,  0.0160,\n",
       "         0.0460,  0.0460, -0.1050, -0.1040, -0.0370, -0.0370,  0.0380,  0.0390,\n",
       "        -0.1910, -0.1880, -0.1000, -0.0990, -0.0560, -0.0560,  0.0120,  0.0130,\n",
       "         0.0060,  0.0070,  0.0680,  0.0680,  0.5620,  0.5630, -0.3370, -0.3350,\n",
       "         0.3710,  0.3710, -0.2260, -0.2270], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1405a1cf-25a9-4b71-ac75-2f5ad2ed11a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sko.PSO import PSO\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class CustomPSO(PSO):\n",
    "    def __init__(self, *args, initial_guess=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if initial_guess is not None:\n",
    "            # Set the first particle to the initial guess\n",
    "            self.X[0] = initial_guess.cpu().numpy()\n",
    "            \n",
    "def calculate_energy(spins, data, pretrained_model):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    num_particles, num_params = spins.shape\n",
    "    num_spins = num_params // 2\n",
    "    magnitudes = spins[:, :num_spins]\n",
    "    directions = spins[:, num_spins:]\n",
    "    spins_magnitude = torch.tensor(magnitudes, dtype=torch.float32, device='cuda:0')\n",
    "    directions = torch.tensor(directions, dtype=torch.float32, device='cuda:0')\n",
    "    directions = torch.round(directions)\n",
    "    directions = torch.clamp(directions, -1, 1)\n",
    "    spin_vectors = torch.stack([torch.zeros_like(directions), torch.zeros_like(directions), directions], dim=2)\n",
    "    \n",
    "    \"\"\"Calculate the total energy of the spin system\"\"\"\n",
    "    data.natoms = torch.Tensor([68])\n",
    "    n_neighbors = []\n",
    "    n_index = data.edge_index[1, :]\n",
    "    n_neighbors.append(n_index.shape[0])\n",
    "    data.neighbors = torch.tensor(n_neighbors)\n",
    "    #update spin direction and spins_magnitude: try 1 don't change direction of spin, and change direction of spin\n",
    "    data.inmag = torch.Tensor(spins_magnitude[0])\n",
    "    data.magft = torch.Tensor(spin_vectors[0])\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    energy_preds, magmom_preds = pretrained_model(data.to(\"cuda:0\"))\n",
    "    \n",
    "    print(data.inmag[:3], data.magft[:,2][:3], energy_preds)\n",
    "    \n",
    "    return energy_preds.item()  # Assuming energy_preds is a tensor of shape (1,)\n",
    "\n",
    "def fitness(flat_spins, data, pretrained_model, num_atoms):\n",
    "    num_particles = flat_spins.size // (2 * num_atoms)\n",
    "    spins = flat_spins.reshape((num_particles, 2 * num_atoms))\n",
    "    return calculate_energy(spins, data, pretrained_model)\n",
    "\n",
    "def pso_spin_optimization(data, pretrained_model, initial_guess=None, num_atoms=68, num_particles=30, num_iterations=100, w=0.8, c1=0.5, c2=0.5):\n",
    "    num_params = 2 * num_atoms\n",
    "    lb = [-8] * num_atoms + [-1] * num_atoms  # [-8, 8] is the boundary for magnitude, [-1, 1] is the boundary for vector\n",
    "    ub = [8] * num_atoms + [1] * num_atoms\n",
    "\n",
    "    # Create the fitness function with frozen data and pretrained_model\n",
    "    fitness_with_params = partial(fitness, data=data, pretrained_model=pretrained_model, num_atoms=num_atoms)\n",
    "    \n",
    "    # Create the PSO instance\n",
    "    pso = CustomPSO(func=fitness_with_params, \n",
    "              n_dim=num_params, \n",
    "              pop=num_particles, \n",
    "              max_iter=num_iterations, \n",
    "              lb=lb, \n",
    "              ub=ub, \n",
    "              w=w, \n",
    "              c1=c1, \n",
    "              c2=c2,\n",
    "              initial_guess = initial_guess\n",
    "                   )\n",
    "    \n",
    "    # Run the PSO optimization\n",
    "    pso.run()\n",
    "\n",
    "    best_positions = np.array(pso.gbest_x).reshape((num_atoms, 2))\n",
    "    best_energy = pso.gbest_y\n",
    "\n",
    "    # best_magnitudes = best_positions[:, 0]\n",
    "    # best_spins = best_positions[:, 1]\n",
    "    \n",
    "    return best_positions, best_energy, pso.gbest_y_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7e970f08-f770-4a98-a23c-9a93afa26af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8553,  6.2995, -1.3603], device='cuda:0') tensor([-0., 1., 1.], device='cuda:0') tensor([[-6.4549]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.0634,  5.1839, -2.7638], device='cuda:0') tensor([ 0.,  0., -1.], device='cuda:0') tensor([[-6.3837]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-0.6858,  2.9729,  7.7322], device='cuda:0') tensor([ 1., -0., -1.], device='cuda:0') tensor([[-6.5693]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 4.3160,  6.0113, -3.8229], device='cuda:0') tensor([-0., 0., -0.], device='cuda:0') tensor([[-6.3549]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-0.4890,  1.8591,  4.8223], device='cuda:0') tensor([0., -0., 1.], device='cuda:0') tensor([[-6.4699]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 6.7566, -5.6765, -3.1352], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7396]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.2352, -6.0751, -7.9409], device='cuda:0') tensor([-0., 0., 1.], device='cuda:0') tensor([[-6.3570]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.1663,  5.0985,  6.4991], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.3935]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.1608, -4.3597, -6.9606], device='cuda:0') tensor([ 0., -0., -1.], device='cuda:0') tensor([[-6.3939]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.5109,  7.6435,  7.9033], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.3256]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.9085, -2.2435, -1.2394], device='cuda:0') tensor([1., 0., 1.], device='cuda:0') tensor([[-6.2699]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.7176, -7.0417,  3.4622], device='cuda:0') tensor([-0., -1., -0.], device='cuda:0') tensor([[-6.3452]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.5766, -3.2228,  3.0153], device='cuda:0') tensor([1., -0., 0.], device='cuda:0') tensor([[-6.4199]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([1.8094, 3.9433, 2.1130], device='cuda:0') tensor([-1.,  1.,  0.], device='cuda:0') tensor([[-6.5283]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.0491,  3.3807,  0.4418], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.4135]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.8890, -2.5510,  6.2526], device='cuda:0') tensor([ 0., -1.,  1.], device='cuda:0') tensor([[-6.5175]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.3246, 1.7475, 4.2262], device='cuda:0') tensor([-1., -1.,  0.], device='cuda:0') tensor([[-6.6068]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.1840,  3.3019, -2.4811], device='cuda:0') tensor([-0., 0., 0.], device='cuda:0') tensor([[-6.2489]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.9363, -0.7145, -4.5642], device='cuda:0') tensor([-1., -0.,  0.], device='cuda:0') tensor([[-6.4990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 7.0001, -1.4718, -6.5980], device='cuda:0') tensor([-0., -0., 0.], device='cuda:0') tensor([[-6.4279]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.9821,  5.9271, -2.1983], device='cuda:0') tensor([-0., 1., -0.], device='cuda:0') tensor([[-6.4297]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 4.7184, -3.4046,  6.1345], device='cuda:0') tensor([0., -0., -0.], device='cuda:0') tensor([[-6.3833]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.8960, -4.2695,  3.7765], device='cuda:0') tensor([0., 0., 1.], device='cuda:0') tensor([[-6.3102]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 6.5384, -6.3730,  4.2880], device='cuda:0') tensor([-1., -0.,  1.], device='cuda:0') tensor([[-6.5074]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.1550,  1.3847, -5.1670], device='cuda:0') tensor([-1., -0., -0.], device='cuda:0') tensor([[-6.4491]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.6269,  2.7786,  2.2348], device='cuda:0') tensor([ 1.,  0., -1.], device='cuda:0') tensor([[-6.3935]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.2663, -6.3998,  2.7592], device='cuda:0') tensor([1., 0., 1.], device='cuda:0') tensor([[-6.3448]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.6367,  4.4092, -5.9844], device='cuda:0') tensor([-0., -0., 0.], device='cuda:0') tensor([[-6.3633]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 4.7608, -2.4244,  0.9016], device='cuda:0') tensor([-0., 0., -0.], device='cuda:0') tensor([[-6.1626]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.5692, -3.8784, -6.2122], device='cuda:0') tensor([0., 1., 0.], device='cuda:0') tensor([[-6.3905]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([5.8103, 6.4149, 0.7791], device='cuda:0') tensor([ 0.,  0., -1.], device='cuda:0') tensor([[-6.6216]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([3.6324, 5.1156, 7.3743], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.6755]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -3.1517,  8.0000], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.7473]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.3068,  1.8231, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.8398]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000, -4.7227,  2.5271], device='cuda:0') tensor([-1.,  0.,  1.], device='cuda:0') tensor([[-6.6933]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.1258,  2.9212, -0.0924], device='cuda:0') tensor([-1.,  1., -0.], device='cuda:0') tensor([[-6.6088]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.2859,  1.1859,  7.2202], device='cuda:0') tensor([-0., 1., -0.], device='cuda:0') tensor([[-6.5664]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.8145,  8.0000,  0.3747], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-6.9130]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -0.1337, -8.0000], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.9640]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.6406,  8.0000,  8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9186]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.7849, -6.5462], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-6.8348]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.5108, -3.8914, -4.8388], device='cuda:0') tensor([-1.,  1., -0.], device='cuda:0') tensor([[-6.7666]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([7.6776, 5.6101, 0.2625], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.7280]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.1969,  8.0000, -6.8766], device='cuda:0') tensor([1., 0., 1.], device='cuda:0') tensor([[-6.7298]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.4062, -8.0000,  7.3710], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.7967]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.6052,  5.5850, -2.1112], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.8090]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000, -8.0000, -5.4188], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-6.6338]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([8., 8., 8.], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.6579]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.8211, -1.0650], device='cuda:0') tensor([-0., -1.,  0.], device='cuda:0') tensor([[-6.8182]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  1.7210, -8.0000], device='cuda:0') tensor([-0.,  0., -1.], device='cuda:0') tensor([[-6.8307]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -0.2010, -4.4216], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.7623]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([8.0000, 8.0000, 2.8153], device='cuda:0') tensor([1., -0., 1.], device='cuda:0') tensor([[-6.7153]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000, -4.7129,  5.6710], device='cuda:0') tensor([0., 1., 1.], device='cuda:0') tensor([[-6.5551]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.2723, -1.3246,  8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7719]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.3524, -8.0000, -2.1103], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8475]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.0462,  0.6106,  8.0000], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.7979]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.4825, -4.6197, -1.0857], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-6.9530]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  3.5431, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.7574]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.7468, -3.8101, -1.5810], device='cuda:0') tensor([1., 1., 0.], device='cuda:0') tensor([[-6.4877]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-0.4885, -3.6478,  6.6011], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.8699]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([8.0000, 8.0000, 1.3768], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.6448]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([0.8349, 3.1960, 8.0000], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.8517]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -7.0014,  7.6149], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.9427]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.3033, -1.5429, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.9100]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000, -8.0000, -2.1694], device='cuda:0') tensor([-1.,  0.,  1.], device='cuda:0') tensor([[-6.8562]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  1.3876], device='cuda:0') tensor([-1.,  1.,  0.], device='cuda:0') tensor([[-6.7515]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.8012,  8.0000], device='cuda:0') tensor([-0.,  1., -1.], device='cuda:0') tensor([[-6.8737]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.4738,  8.0000, -5.4770], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-7.0731]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  3.2472, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1453]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.1429,  7.1135,  2.6109], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0264]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-7.0077]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.7424, -0.9580, -8.0000], device='cuda:0') tensor([-1.,  1., -0.], device='cuda:0') tensor([[-6.8991]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.7016,  8.0000, -5.2061], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-7.0018]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([1., -0., 1.], device='cuda:0') tensor([[-6.8394]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8., -8.,  8.], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.9201]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.0235,  8.0000, -8.0000], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.9667]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 7.8040, -8.0000, -8.0000], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-6.8571]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([8., 8., 8.], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.9054]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  1.4407], device='cuda:0') tensor([-0., -1.,  0.], device='cuda:0') tensor([[-6.8684]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  3.5911, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-7.0233]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -5.0829, -6.8478], device='cuda:0') tensor([ 1.,  0., -1.], device='cuda:0') tensor([[-6.9255]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  8.0000, -1.0650], device='cuda:0') tensor([0., -0., 1.], device='cuda:0') tensor([[-6.8179]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000, -3.1076,  0.3928], device='cuda:0') tensor([-0., 1., 0.], device='cuda:0') tensor([[-6.7940]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.7115,  3.1455,  8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9619]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -8.0000,  0.2705], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9063]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.2751, -1.1418,  8.0000], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.9224]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 3.0914, -2.0483, -4.6362], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-7.0381]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  2.2428, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.9657]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -3.5688, -5.8359], device='cuda:0') tensor([1., 1., 0.], device='cuda:0') tensor([[-6.8506]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.5962, -2.5108,  8.0000], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.9732]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  8.0000, -0.9780], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.9046]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.2016,  1.6850,  8.0000], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.9214]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -6.9014,  5.4227], device='cuda:0') tensor([1., 1., 1.], device='cuda:0') tensor([[-6.9471]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.5968, -2.6707, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.8751]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 7.0480, -8.0000, -7.8366], device='cuda:0') tensor([-1.,  0.,  0.], device='cuda:0') tensor([[-6.7969]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -1.2978], device='cuda:0') tensor([-1.,  1., -0.], device='cuda:0') tensor([[-6.7078]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8.,  8.], device='cuda:0') tensor([-0.,  0., -1.], device='cuda:0') tensor([[-6.8812]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-7.0071]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.9518, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1961]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.8973,  6.1502, -4.5157], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9410]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9721]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.0725,  2.1052, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-7.0256]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.0295,  8.0000, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.9580]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 1., -1.,  0.], device='cuda:0') tensor([[-6.8906]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 4.5580, -8.0000,  8.0000], device='cuda:0') tensor([ 1.,  1., -1.], device='cuda:0') tensor([[-6.9363]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.8276]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 6.8858, -8.0000, -8.0000], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-6.9746]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([7.0760, 8.0000, 8.0000], device='cuda:0') tensor([ 1.,  0., -1.], device='cuda:0') tensor([[-6.7818]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  2.6884], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.8487]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.6829,  5.0115, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9846]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -6.9900, -8.0000], device='cuda:0') tensor([ 1., -0., -1.], device='cuda:0') tensor([[-6.7528]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  8.0000, -4.7127], device='cuda:0') tensor([ 0., -1.,  1.], device='cuda:0') tensor([[-6.8719]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 8.0000,  0.6013, -7.2328], device='cuda:0') tensor([-1.,  1., -0.], device='cuda:0') tensor([[-6.8926]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.7465,  8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0056]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -8.0000, -0.5861], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9647]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.1425, -1.0541,  8.0000], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.7128]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.0392,  0.9878, -7.7738], device='cuda:0') tensor([-1., -1., -0.], device='cuda:0') tensor([[-7.0428]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  1.2079, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.9026]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -1.2558, -8.0000], device='cuda:0') tensor([1., 1., -0.], device='cuda:0') tensor([[-6.9033]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([1.2438, 0.1950, 7.4321], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.8342]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.2763,  8.0000, -4.1868], device='cuda:0') tensor([ 1.,  0., -1.], device='cuda:0') tensor([[-6.9374]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.9287,  2.5423,  6.4858], device='cuda:0') tensor([1., 1., 0.], device='cuda:0') tensor([[-6.7260]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -2.8507,  1.6024], device='cuda:0') tensor([-0., 0., -0.], device='cuda:0') tensor([[-6.9441]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.1467, -1.0746, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.6878]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.8240, -6.1902, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.6325]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -4.5568], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.6015]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  5.3611], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.8990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-6.8502]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1921]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.4561, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7611]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8468]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.6179,  5.9744, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-7.0048]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.9038,  8.0000, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.9541]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.9280]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.8072, -8.0000,  3.6755], device='cuda:0') tensor([ 0.,  0., -1.], device='cuda:0') tensor([[-6.9531]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 1., -1.,  1.], device='cuda:0') tensor([[-6.8130]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.5034, -4.7439, -8.0000], device='cuda:0') tensor([-1., -1.,  1.], device='cuda:0') tensor([[-6.9819]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([1.8650, 8.0000, 4.2328], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.7570]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  0.3890], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.7701]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.4183,  6.5074, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8577]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -7.2055, -8.0000], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.8639]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 3.2322,  8.0000, -8.0000], device='cuda:0') tensor([-0., -1.,  0.], device='cuda:0') tensor([[-6.7988]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 7.1141,  3.8959, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.8193]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  4.3551], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0027]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -8.0000, -2.9980], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8742]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.4950,  1.9079,  7.5850], device='cuda:0') tensor([ 1., -1., -1.], device='cuda:0') tensor([[-6.8944]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.3178,  3.6989, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0505]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  2.8465, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.6695]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  0.6964, -8.0000], device='cuda:0') tensor([1., 1., -0.], device='cuda:0') tensor([[-6.6138]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.5473,  3.7196,  2.1452], device='cuda:0') tensor([ 0., -1.,  0.], device='cuda:0') tensor([[-6.7728]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-2.8532,  8.0000, -6.9628], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-6.9044]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  3.5316,  1.0906], device='cuda:0') tensor([ 0.,  1., -1.], device='cuda:0') tensor([[-6.8935]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  3.3464, -3.7186], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-7.0923]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.5277,  3.3577, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9292]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.4090, -0.4870, -6.9953], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.7066]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -7.1706], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.8651]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000,  2.1186], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0284]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.8776]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.7983, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1917]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.7269, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7561]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0866]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.8674,  7.9979, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.9168]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.3309,  8.0000, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-7.0033]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.3732, -8.0000], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-7.1219]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -7.3714, -1.2125], device='cuda:0') tensor([-0., -0., -1.], device='cuda:0') tensor([[-6.9645]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([ 0., -1.,  1.], device='cuda:0') tensor([[-6.8100]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-0.1617, -1.1075, -8.0000], device='cuda:0') tensor([-1., -1., -0.], device='cuda:0') tensor([[-7.0058]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.1504,  8.0000, -0.0521], device='cuda:0') tensor([ 0., -1., -1.], device='cuda:0') tensor([[-6.8365]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -4.3098], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9324]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.4605,  6.6760, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8830]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -5.7641, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0098]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.4189,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -0.], device='cuda:0') tensor([[-6.9879]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 2.0017,  6.8159, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.9830]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -1.4472], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0256]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -3.2980, -5.9409], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0359]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.8870,  5.2489,  1.8175], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-6.8321]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.9462, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0369]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.3564, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9629]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  1.9995, -8.0000], device='cuda:0') tensor([ 0., -0., -1.], device='cuda:0') tensor([[-6.8038]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.3202,  5.4398, -0.2935], device='cuda:0') tensor([-0., -1., -0.], device='cuda:0') tensor([[-6.6634]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-7.0776]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.8031,  4.3324, -4.5782], device='cuda:0') tensor([ 0.,  1., -1.], device='cuda:0') tensor([[-6.9991]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0072]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.6097,  7.3478, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1568]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.0985,  4.9965, -4.1244], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8766]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0944]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -2.8145], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0983]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9457]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.0866, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1929]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.7214, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8964]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1059]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.5123,  7.3729, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.9886]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-7.0090]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.2967, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1997]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -6.8245, -5.3737], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1452]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-0., -1., -0.], device='cuda:0') tensor([[-6.7962]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.9466,  3.6809, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1036]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.4033,  8.0000, -3.8213], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-7.0663]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.3584, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1349]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.1797,  6.1603, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9267]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -3.2899, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0498]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.1987,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1894]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-4.6423,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1574]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8631, -6.0965], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1848]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  2.9429, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1940]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.4712,  7.5226, -5.5028], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0073]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1563]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.9474, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9216]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  3.7494, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0425]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.1401,  6.1907, -1.2744], device='cuda:0') tensor([-0., -1., -0.], device='cuda:0') tensor([[-6.9753]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1530]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.7292,  5.8359, -8.0000], device='cuda:0') tensor([ 0.,  0., -1.], device='cuda:0') tensor([[-7.0453]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1208]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1960]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -1.8557], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0345]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2001]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -7.3618], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1551]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.6094,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9576]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.9171, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1932]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.5295,  7.4931, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9551]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8926, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1221]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-5.2092,  4.5268, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-7.0208]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1444]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.4355, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1959]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000, -2.6354, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1612]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.9896,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.9251]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8193, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1909]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -7.6440], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2043]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.5242, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1914]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 0.5386,  4.8011, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8838]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  2.3495, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1122]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.7470, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1912]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1981]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.3718, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1935]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1914]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1267]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1574]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.8585, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8894]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.3967, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1640]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.9449,  6.8184, -2.4956], device='cuda:0') tensor([-0., -1., -1.], device='cuda:0') tensor([[-7.0790]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1925]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.6970,  7.2227, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-7.1534]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1930]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1912]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -2.7621], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.0747]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2017]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1555]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.2003,  8.0000, -7.6979], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7417]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.9426, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1936]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.9669,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8265]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8286, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1581]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-3.1314,  2.7464, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.8534]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1888]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.7997, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1959]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  4.6128, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1876]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.7391,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -0.], device='cuda:0') tensor([[-6.8514]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1911]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2016]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.1456, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1856]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 4.1807,  4.6089, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.7483]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.5573, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1477]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.6600, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1923]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1922]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.0107, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1915]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1945]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1540]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1970]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.5861, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.6528]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.2048, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1766]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.5575, -4.0531], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1414]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1668]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.7307,  8.0000, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-7.1550]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1914]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1917]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -3.6801], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1510]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1967]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1982]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.9031,  8.0000, -7.2880], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.7557]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.0441, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1967]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.6636,  8.0000, -5.7816], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.6598]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8120, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1904]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-1.4066,  2.6457, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.6862]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1904]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.0491, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1985]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1885]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.2004,  8.0000, -8.0000], device='cuda:0') tensor([-0., -1.,  0.], device='cuda:0') tensor([[-6.5788]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1955]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1959]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  6.5579, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1881]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 5.8085,  5.5830, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.7548]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1865]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.7412, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1938]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1918]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.0192, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1945]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1983]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1982]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  5.7179, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.6870]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1986]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -6.5851], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1980]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1579]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-7.8043,  8.0000, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1927]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1953]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1929]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  8.0000, -4.4429], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1545]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1897]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2023]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.9935,  8.0000, -6.4488], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.8375]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.1024, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1963]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.7683,  8.0000, -1.7493], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-6.6056]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.8314, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1900]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-0.3184,  4.9220, -8.0000], device='cuda:0') tensor([-1.,  0., -1.], device='cuda:0') tensor([[-6.6338]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1946]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1988]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1897]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-6.2018,  8.0000, -8.0000], device='cuda:0') tensor([-0., -1.,  1.], device='cuda:0') tensor([[-6.7494]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1960]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.1194, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1960]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([ 1.1869,  6.6242, -8.0000], device='cuda:0') tensor([-1., -0., -1.], device='cuda:0') tensor([[-6.6836]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1930]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.9342, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1946]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1936]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  7.4996, -8.0000], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1971]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2022]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2030]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.1992]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.0000,  4.5220, -8.0000], device='cuda:0') tensor([-1.,  1., -1.], device='cuda:0') tensor([[-6.6732]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2050]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([-8.,  8., -8.], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0') tensor([[-7.2006]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Best Energy: [-7.20501852]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "data = torch.load(\"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_6.pt\").to(\"cuda:0\")\n",
    "checkpoint = \"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/magmom_checkpoints/right/Large_schnet_Einmag_all_application_91split_withoutoverlap-epoch=456-step=228043-val_loss=0.0257.ckpt\"\n",
    "pretrained_model = MagmomClassifier.load_from_checkpoint(checkpoint_path=checkpoint,\n",
    "                                                         backbone=schnet_onehot_inmag)\n",
    "\n",
    "\n",
    "initial_guess = torch.cat([data.inmag, data.magft[:,2]])\n",
    "\n",
    "best_positions, best_energy, gbest_y_hist= pso_spin_optimization(data=data, \n",
    "                                                                     pretrained_model=pretrained_model, \n",
    "                                                                     initial_guess=initial_guess, \n",
    "                                                                     num_iterations=10)\n",
    "\n",
    "#print(\"Best Spin Configuration (Magnitude, Direction):\", best_configuration)\n",
    "print(\"Best Energy:\", best_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9de0845c-4ab8-49fe-8a41-309bbbdfe735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.0000,  8.0000, -8.0000, -7.9256,  8.0000,  8.0000,  8.0000, -5.4742,\n",
       "        -8.0000, -8.0000,  3.9890,  1.9358,  8.0000,  1.4101, -8.0000,  8.0000,\n",
       "         8.0000,  8.0000,  0.7090,  3.8357, -3.6506,  8.0000,  5.2483, -8.0000,\n",
       "        -8.0000,  6.0082, -8.0000,  8.0000, -0.8189,  8.0000,  8.0000, -8.0000,\n",
       "         8.0000, -8.0000, -8.0000,  2.2249,  8.0000, -4.8758,  5.9336, -4.5947,\n",
       "         0.7218,  8.0000,  7.9770, -5.0866, -4.6392, -8.0000, -8.0000, -7.0004,\n",
       "         8.0000, -8.0000,  8.0000,  2.7950, -8.0000, -6.6147, -6.4196,  8.0000,\n",
       "        -2.6948,  3.4365,  8.0000,  2.0739,  6.9129,  8.0000,  7.3598,  8.0000,\n",
       "         8.0000,  8.0000, -5.1358, -8.0000], device='cuda:0')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.inmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d5e55e37-bc8c-4e17-a4dc-b9128761c530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(gbest_y_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ee078-2d8c-48a2-b458-dd9c7e88a5f6",
   "metadata": {},
   "source": [
    "# search PSO hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4280715e-1ab5-4e87-9bcf-588be0e6c975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Best fit: -7.244770526885986\n",
      "Iter: 50, Best fit: -7.3172197341918945\n",
      "Iter: 100, Best fit: -7.3336076736450195\n",
      "Iter: 150, Best fit: -7.341277122497559\n",
      "Iter: 200, Best fit: -7.345366477966309\n",
      "Iter: 250, Best fit: -7.3496809005737305\n",
      "Iter: 300, Best fit: -7.354484558105469\n",
      "Iter: 350, Best fit: -7.355637073516846\n",
      "Iter: 400, Best fit: -7.356513023376465\n",
      "Iter: 450, Best fit: -7.35679292678833\n",
      "Iter: 500, Best fit: -7.356967926025391\n",
      "Iter: 550, Best fit: -7.357541084289551\n",
      "Iter: 600, Best fit: -7.35764741897583\n",
      "Iter: 650, Best fit: -7.357667922973633\n",
      "Iter: 700, Best fit: -7.357690811157227\n",
      "Iter: 750, Best fit: -7.35833215713501\n",
      "Iter: 800, Best fit: -7.358905792236328\n",
      "Iter: 850, Best fit: -7.359270095825195\n",
      "Iter: 900, Best fit: -7.35933780670166\n",
      "Iter: 950, Best fit: -7.360561847686768\n",
      "Iter: 1000, Best fit: -7.360581398010254\n",
      "Iter: 1050, Best fit: -7.360598564147949\n",
      "Iter: 1100, Best fit: -7.360646724700928\n",
      "Iter: 1150, Best fit: -7.360647678375244\n",
      "Iter: 1200, Best fit: -7.360659599304199\n",
      "Iter: 1250, Best fit: -7.360667705535889\n",
      "Iter: 1300, Best fit: -7.360668659210205\n",
      "Iter: 1350, Best fit: -7.36067008972168\n",
      "Iter: 1400, Best fit: -7.36067008972168\n",
      "Iter: 1450, Best fit: -7.36067008972168\n",
      "Iter: 1500, Best fit: -7.36067008972168\n",
      "Iter: 1550, Best fit: -7.360671043395996\n",
      "Iter: 1600, Best fit: -7.3606719970703125\n",
      "Iter: 1650, Best fit: -7.3606743812561035\n",
      "Iter: 1700, Best fit: -7.360683441162109\n",
      "Iter: 1750, Best fit: -7.360683917999268\n",
      "Iter: 1800, Best fit: -7.360684871673584\n",
      "Iter: 1850, Best fit: -7.360684871673584\n",
      "Iter: 1900, Best fit: -7.360684871673584\n",
      "Iter: 1950, Best fit: -7.360685348510742\n",
      "Iter: 2000, Best fit: -7.360686302185059\n",
      "Iter: 2050, Best fit: -7.360686302185059\n",
      "Iter: 2100, Best fit: -7.360686302185059\n",
      "Iter: 2150, Best fit: -7.360686302185059\n",
      "Iter: 2200, Best fit: -7.360714912414551\n",
      "Iter: 2250, Best fit: -7.360714912414551\n",
      "Iter: 2300, Best fit: -7.360714912414551\n",
      "Iter: 2350, Best fit: -7.360714912414551\n",
      "Iter: 2400, Best fit: -7.360714912414551\n",
      "Iter: 2450, Best fit: -7.360714912414551\n",
      "Iter: 2500, Best fit: -7.360714912414551\n",
      "Iter: 2550, Best fit: -7.360714912414551\n",
      "Iter: 2600, Best fit: -7.360714912414551\n",
      "Iter: 2650, Best fit: -7.360715389251709\n",
      "Iter: 2700, Best fit: -7.360715389251709\n",
      "Iter: 2750, Best fit: -7.360715389251709\n",
      "Iter: 2800, Best fit: -7.360715389251709\n",
      "Iter: 2850, Best fit: -7.360715389251709\n",
      "Iter: 2900, Best fit: -7.360715389251709\n",
      "Iter: 2950, Best fit: -7.360715389251709\n",
      "Iter: 3000, Best fit: -7.360715389251709\n",
      "Iter: 3050, Best fit: -7.360715389251709\n",
      "Iter: 3100, Best fit: -7.360715389251709\n",
      "Iter: 3150, Best fit: -7.360715389251709\n",
      "Iter: 3200, Best fit: -7.360715389251709\n",
      "Iter: 3250, Best fit: -7.360715389251709\n",
      "Iter: 3300, Best fit: -7.360715389251709\n",
      "Iter: 3350, Best fit: -7.360715389251709\n",
      "Iter: 3400, Best fit: -7.360715389251709\n",
      "Iter: 3450, Best fit: -7.360715389251709\n",
      "Iter: 3500, Best fit: -7.360715389251709\n",
      "Iter: 3550, Best fit: -7.360715389251709\n",
      "Iter: 3600, Best fit: -7.360715389251709\n",
      "Iter: 3650, Best fit: -7.360715389251709\n",
      "Iter: 3700, Best fit: -7.360715389251709\n",
      "Iter: 3750, Best fit: -7.361141204833984\n",
      "Iter: 3800, Best fit: -7.361186981201172\n",
      "Iter: 3850, Best fit: -7.361203193664551\n",
      "Iter: 3900, Best fit: -7.361203670501709\n",
      "Iter: 3950, Best fit: -7.361203670501709\n",
      "Iter: 4000, Best fit: -7.361203670501709\n",
      "Iter: 4050, Best fit: -7.361203670501709\n",
      "Iter: 4100, Best fit: -7.361203670501709\n",
      "Iter: 4150, Best fit: -7.361204624176025\n",
      "Iter: 4200, Best fit: -7.361204624176025\n",
      "Iter: 4250, Best fit: -7.361206531524658\n",
      "Iter: 4300, Best fit: -7.361206531524658\n",
      "Iter: 4350, Best fit: -7.361206531524658\n",
      "Iter: 4400, Best fit: -7.361207008361816\n",
      "Iter: 4450, Best fit: -7.361207485198975\n",
      "Iter: 4500, Best fit: -7.361207485198975\n",
      "Iter: 4550, Best fit: -7.361207485198975\n",
      "Iter: 4600, Best fit: -7.361207485198975\n",
      "Iter: 4650, Best fit: -7.361207485198975\n",
      "Iter: 4700, Best fit: -7.361209869384766\n",
      "Iter: 4750, Best fit: -7.361209869384766\n",
      "Iter: 4800, Best fit: -7.361209869384766\n",
      "Iter: 4850, Best fit: -7.361209869384766\n",
      "Iter: 4900, Best fit: -7.361209869384766\n",
      "Iter: 4950, Best fit: -7.361210346221924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "class CustomPSO:\n",
    "    def __init__(self, func, n_dim, pop=40, max_iter=150, lb=-1e5, ub=1e5, w=0.8, c1=0.5, c2=0.5, initial_guess=None):\n",
    "        self.func = func\n",
    "        self.n_dim = n_dim\n",
    "        self.pop = pop\n",
    "        self.max_iter = max_iter\n",
    "        self.lb = torch.tensor(lb * np.ones(self.n_dim), device='cuda:0', dtype=torch.float32)\n",
    "        self.ub = torch.tensor(ub * np.ones(self.n_dim), device='cuda:0', dtype=torch.float32)\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "        assert self.n_dim == len(self.lb) == len(self.ub), 'dim == len(lb) == len(ub) is not True'\n",
    "        assert torch.all(self.ub > self.lb), 'upper-bound must be greater than lower-bound'\n",
    "\n",
    "        # Initialize particles' positions\n",
    "        self.X = torch.rand((self.pop, self.n_dim), device='cuda:0') * (self.ub - self.lb) + self.lb\n",
    "        if initial_guess is not None:\n",
    "            self.X[0] = initial_guess  # Set the first particle to the initial guess\n",
    "            # print(\"Initial guess set for the first particle:\", self.X[0].cpu().numpy())  # Debug statement\n",
    "\n",
    "        # Initialize particles' velocities\n",
    "        v_high = self.ub - self.lb\n",
    "        self.V = torch.rand((self.pop, self.n_dim), device='cuda:0') * 2 * v_high - v_high\n",
    "\n",
    "        # Evaluate initial fitness\n",
    "        self.Y = torch.tensor([self.func(x) for x in self.X], device='cuda:0', dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        # Initialize personal best positions and values\n",
    "        self.pbest_x = self.X.clone()\n",
    "        self.pbest_y = self.Y.clone()\n",
    "\n",
    "        # Initialize global best position and value\n",
    "        self.gbest_x = self.pbest_x[self.pbest_y.argmin()].clone()\n",
    "        self.gbest_y = self.pbest_y.min()\n",
    "        self.gbest_y_hist = []\n",
    "\n",
    "    def update_V(self):\n",
    "        r1 = torch.rand((self.pop, self.n_dim), device='cuda:0')\n",
    "        r2 = torch.rand((self.pop, self.n_dim), device='cuda:0')\n",
    "        self.V = self.w * self.V + \\\n",
    "                 self.c1 * r1 * (self.pbest_x - self.X) + \\\n",
    "                 self.c2 * r2 * (self.gbest_x - self.X)\n",
    "\n",
    "    def update_X(self):\n",
    "        self.X = self.X + self.V\n",
    "        self.X = torch.max(torch.min(self.X, self.ub), self.lb)\n",
    "\n",
    "    def cal_y(self):\n",
    "        self.Y = torch.tensor([self.func(x) for x in self.X], device='cuda:0', dtype=torch.float32).reshape(-1, 1)\n",
    "        return self.Y\n",
    "\n",
    "    def update_pbest(self):\n",
    "        mask = self.Y < self.pbest_y\n",
    "        self.pbest_x = torch.where(mask, self.X, self.pbest_x)\n",
    "        self.pbest_y = torch.where(mask, self.Y, self.pbest_y)\n",
    "\n",
    "    def update_gbest(self):\n",
    "        idx_min = self.pbest_y.argmin()\n",
    "        if self.gbest_y > self.pbest_y[idx_min]:\n",
    "            self.gbest_x = self.pbest_x[idx_min].clone()\n",
    "            self.gbest_y = self.pbest_y[idx_min]\n",
    "\n",
    "    def run(self):\n",
    "        for iter_num in range(self.max_iter):\n",
    "            self.update_V()\n",
    "            self.update_X()\n",
    "            self.cal_y()\n",
    "            self.update_pbest()\n",
    "            self.update_gbest()\n",
    "\n",
    "            self.gbest_y_hist.append(self.gbest_y.item())\n",
    "            if iter_num % 50 == 0:\n",
    "                #print(f'Iter: {iter_num}, Best fit: {self.gbest_y.item()} at {self.gbest_x.cpu().numpy()}')\n",
    "                \n",
    "                print(f'Iter: {iter_num}, Best fit: {self.gbest_y.item()}')\n",
    "\n",
    "        return self.gbest_x, self.gbest_y\n",
    "\n",
    "def calculate_energy(spins, data, pretrained_model):\n",
    "    num_particles, num_params = spins.shape\n",
    "    num_spins = num_params // 2\n",
    "    magnitudes = spins[:, :num_spins]\n",
    "    directions = spins[:, num_spins:]\n",
    "    spins_magnitude = magnitudes\n",
    "    directions = directions\n",
    "    directions = torch.round(directions)\n",
    "    directions = torch.clamp(directions, -1, 1)\n",
    "    spin_vectors = torch.stack([torch.zeros_like(directions), torch.zeros_like(directions), directions], dim=2)\n",
    "\n",
    "    \"\"\"Calculate the total energy of the spin system\"\"\"\n",
    "    data.natoms = torch.tensor([68], device='cuda:0')\n",
    "    n_neighbors = []\n",
    "    n_index = data.edge_index[1, :]\n",
    "    n_neighbors.append(n_index.shape[0])\n",
    "    data.neighbors = torch.tensor(n_neighbors, device='cuda:0')\n",
    "    # update spin direction and spins_magnitude: try 1 don't change direction of spin, and change direction of spin\n",
    "    data.inmag = spins_magnitude[0]\n",
    "    data.magft = spin_vectors[0]\n",
    "\n",
    "    energy_preds, magmom_preds = pretrained_model(data.to(\"cuda:0\"))\n",
    "\n",
    "    return energy_preds.item()  # Assuming energy_preds is a tensor of shape (1,)\n",
    "\n",
    "def fitness(flat_spins, data, pretrained_model, num_atoms):\n",
    "    num_particles = flat_spins.size(0) // (2 * num_atoms)\n",
    "    spins = flat_spins.view(num_particles, 2 * num_atoms)\n",
    "    return calculate_energy(spins, data, pretrained_model)\n",
    "\n",
    "def pso_spin_optimization(data, pretrained_model, initial_guess=None, num_atoms=68, num_particles=30, num_iterations=100, w=0.8, c1=1.5, c2=1.5):\n",
    "    num_params = 2 * num_atoms\n",
    "    lb = [-20] * num_atoms + [-1] * num_atoms  # [-8, 8] is the boundary for magnitude, [-1, 1] is the boundary for vector\n",
    "    ub = [20] * num_atoms + [1] * num_atoms\n",
    "\n",
    "    # Create the fitness function with frozen data and pretrained_model\n",
    "    fitness_with_params = partial(fitness, data=data, pretrained_model=pretrained_model, num_atoms=num_atoms)\n",
    "\n",
    "    # Create the CustomPSO instance\n",
    "    pso = CustomPSO(func=fitness_with_params, \n",
    "                    n_dim=num_params, \n",
    "                    pop=num_particles, \n",
    "                    max_iter=num_iterations, \n",
    "                    lb=lb, \n",
    "                    ub=ub, \n",
    "                    w=w, \n",
    "                    c1=c1, \n",
    "                    c2=c2,\n",
    "                    initial_guess=initial_guess)\n",
    "\n",
    "    # # Verify initial guess is set correctly\n",
    "    # print(\"Initial guess in optimization function:\", initial_guess.cpu().numpy())  # Debug statement\n",
    "    # print(\"Initial positions in PSO before run:\", pso.X.cpu().numpy())  # Debug statement\n",
    "\n",
    "    # Run the PSO optimization\n",
    "    best_x, best_y = pso.run()\n",
    "\n",
    "    best_positions = best_x.view(num_atoms, 2).cpu().numpy()\n",
    "    best_energy = best_y.item()\n",
    "\n",
    "    return best_positions, best_energy, pso.gbest_y_hist\n",
    "\n",
    "\n",
    "\n",
    "#params = {'c1': 2.0, 'c2': 1.0, 'num_iterations': 1000, 'num_particles': 20, 'w': 0.7}\n",
    "\n",
    "\n",
    "#params = {'c1': 2.0, 'c2': 1.0, 'num_iterations': 1000, 'num_particles': 50, 'w': 0.7}\n",
    "\n",
    "params = {'c1': 2.0, 'c2': 2.0, 'num_iterations': 5000, 'num_particles': 30, 'w': 0.2}\n",
    "\n",
    "# Example usage\n",
    "data = torch.load(\"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_paper/chgnet_Elabel_applications/surface/processed/data_6.pt\").to(\"cuda:0\")\n",
    "checkpoint = \"/pscratch/sd/w/wenxu/jobs/OCP/github_rep/ocp_mag_chgnet_new/magmom_checkpoints/right/Large_schnet_Einmag_all_application_91split_withoutoverlap-epoch=456-step=228043-val_loss=0.0257.ckpt\"\n",
    "pretrained_model = MagmomClassifier.load_from_checkpoint(checkpoint_path=checkpoint,\n",
    "                                                         backbone=schnet_onehot_inmag)\n",
    "\n",
    "initial_magnitudes = data.inmag.cpu().flatten()\n",
    "initial_directions = data.magft[:, 2].cpu().flatten()\n",
    "\n",
    "initial_guess = torch.cat((initial_magnitudes, initial_directions)).to(\"cuda:0\")\n",
    "\n",
    "best_positions, best_energy, energy_history = pso_spin_optimization(data=data, \n",
    "                                                                    pretrained_model=pretrained_model,\n",
    "                                                                    initial_guess=initial_guess, \n",
    "                                                                    **params)\n",
    "# print(\"Best Spin Configuration (Magnitude, Direction):\", best_positions)\n",
    "# print(\"Best Energy:\", best_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae94208-6063-4337-b1b3-4896a772078c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-cu117",
   "language": "python",
   "name": "ocp-cu117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
